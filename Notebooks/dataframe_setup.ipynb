{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate RNA seq DataFrame\n",
    "\n",
    "The tsv file containing the RNA sequencing results are parsed, cleaned and then restricted based on parameters provided by the user. A DataFrame containing the parsed RNA seq data is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variables for processing of RNA seq and SILAC files into DataFrames\n",
    "class ArgBin:\n",
    "    def __init__(\n",
    "                    self, rna_in_path_, prot_in_path_, pair_in_path_, rna_out_path_=Path(Path.cwd() / \"rna_df.xlsx\"), \n",
    "                    prot_out_path_=Path(Path.cwd() / \"prot_df.xlsx\"), comb_out_path_=Path(Path.cwd() / \"comb_df.xlsx\"), \n",
    "                    sample_=None, terms_=None, search_locs_=\"nr_description\", universal_=False, dump_=False, restrict_=False\n",
    "                ):\n",
    "        \n",
    "        self.rna_in_path = rna_in_path_\n",
    "        self.prot_in_path = prot_in_path_\n",
    "        self.pair_in_path = pair_in_path_\n",
    "        self.rna_out_path = rna_out_path_\n",
    "        self.prot_out_path = prot_out_path_\n",
    "        self.comb_out_path = comb_out_path_\n",
    "        self.sample = sample_\n",
    "        self.terms = [] if terms_ is None else terms_\n",
    "        self.search_locs = search_locs_\n",
    "        self.universal = universal_\n",
    "        self.dump = dump_\n",
    "        self.restrict = restrict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rna_df(df, args):\n",
    "    # Drop redundant column\n",
    "    df.drop(\"transcript_id(s)\", axis=1, inplace=True)\n",
    "\n",
    "    # Rename columns where helpful\n",
    "    rename_dict = {\n",
    "                    \"Cellular Components\": \"cell_component\", \"Molecular Function\": \"mol_func\", \n",
    "                    \"Biological Process\": \"bio_process\", \"Kegg Orthology\": \"kegg_orth\",\n",
    "                    \"Nr Description\": \"nr_description\"\n",
    "                  }\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # Fill empty cells with placeholder\n",
    "    df.fillna(\"NaN\", inplace=True)\n",
    "\n",
    "    # Take sample of input data if requested \n",
    "    if args.sample:\n",
    "        df = df.sample(min(df.shape[0], args.sample))\n",
    "\n",
    "    # Add mean and standard deviation columns\n",
    "    df[\"AS_mean\"] = df[[\"AS_1_FPKM\", \"AS_2_FPKM\", \"AS_3_FPKM\"]].mean(axis=1)\n",
    "    df[\"AS_stdev\"] = df[[\"AS_1_FPKM\", \"AS_2_FPKM\", \"AS_3_FPKM\"]].std(axis=1)\n",
    "    df[\"NS_mean\"] = df[[\"NS_1_FPKM\", \"NS_2_FPKM\", \"NS_3_FPKM\"]].mean(axis=1)\n",
    "    df[\"NS_stdev\"] = df[[\"NS_1_FPKM\", \"NS_2_FPKM\", \"NS_3_FPKM\"]].std(axis=1)\n",
    "    df[\"YPD_mean\"] = df[[\"YPD_1_FPKM\", \"YPD_2_FPKM\", \"YPD_3_FPKM\"]].mean(axis=1)\n",
    "    df[\"YPD_stdev\"] = df[[\"YPD_1_FPKM\", \"YPD_2_FPKM\", \"YPD_3_FPKM\"]].std(axis=1)\n",
    "\n",
    "    # Add log2-fold change columns\n",
    "    YPD_log2 = np.log2(df[\"YPD_mean\"] + 1)\n",
    "    NS_log2 = np.log2(df[\"NS_mean\"] + 1)\n",
    "    AS_log2 = np.log2(df[\"AS_mean\"] + 1)\n",
    "    \n",
    "    df[\"YN_L2FC\"] = NS_log2 - YPD_log2\n",
    "    df[\"YA_L2FC\"] = AS_log2 - YPD_log2\n",
    "    df[\"AN_L2FC\"] = AS_log2 - NS_log2\n",
    "\n",
    "    # Add gene_name column with info extracted from \"nr_description\"\n",
    "    df[\"gene_name\"] = df[\"nr_description\"].apply(get_gene_name)\n",
    "\n",
    "    # Add accession column with info extracted form \"nr_description\"\n",
    "    df[\"accession\"] = df[\"nr_description\"].apply(get_accession)\n",
    "\n",
    "    # Add (n) extension to duplicate gene names\n",
    "    dups = df[df.duplicated(subset=\"gene_name\")]\n",
    "    count = Counter() # Tracks the number of instances of each duplicate\n",
    "    for index, row in dups.iterrows():\n",
    "        count.update([str(row.gene_name)])\n",
    "        # New name appends (n) to original name with n being the number of instances observed thus far\n",
    "        new_name = (row.gene_name + \" (\" + (str(count[row.gene_name]) + \")\"))\n",
    "        # Update gene_name by index in the master DataFrame\n",
    "        df.at[index, \"gene_name\"] = new_name\n",
    "\n",
    "    # Rearange columns\n",
    "    reorder_list = [   \n",
    "                        \"gene_id\", \"accession\", \"gene_name\", \"AS_1_FPKM\", \"AS_2_FPKM\", \"AS_3_FPKM\", \"AS_mean\", \"AS_stdev\", \n",
    "                        \"NS_1_FPKM\", \"NS_2_FPKM\", \"NS_3_FPKM\", \"NS_mean\", \"NS_stdev\", \"YPD_1_FPKM\", \"YPD_2_FPKM\", \n",
    "                        \"YPD_3_FPKM\", \"YPD_mean\", \"YPD_stdev\", \"YA_L2FC\", \"YN_L2FC\", \"AN_L2FC\", \"Cellular Component\", \"mol_func\", \n",
    "                        \"bio_process\", \"kegg_orth\", \"nr_description\"\n",
    "                   ]\n",
    "\n",
    "    return df[reorder_list]\n",
    "\n",
    "def get_gene_name(str_):\n",
    "    # First regex catches most gene names\n",
    "    re_1  = re.compile(r\".+//(.+)\\s+\\[\")\n",
    "    # Second regex catches all others that are not \"NaN\"\n",
    "    re_2 = re.compile(r\"Full=([^;]+)\")\n",
    "    re_hit_1 = re.search(re_1, str_)\n",
    "    if re_hit_1 is not None:\n",
    "        return re_hit_1.group(1)\n",
    "\n",
    "    re_hit_2 = re.search(re_2, str_)\n",
    "    if re_hit_2 is not None:\n",
    "        return re_hit_2.group(1)\n",
    "    \n",
    "    # Return \"NaN\" if no gene name found\n",
    "    return \"NaN\"\n",
    "\n",
    "def get_accession(str_):\n",
    "    re_1  = re.compile(r\"(.+)//\")\n",
    "    re_hit_1 = re.search(re_1, str_)\n",
    "    if re_hit_1 is not None:\n",
    "        return re_hit_1.group(1)\n",
    "    \n",
    "    # Return \"NaN\" if no accession number found\n",
    "    return \"NaN\"\n",
    "\n",
    "def search_df(df, _terms, locs, global_search=False, restrict=False):\n",
    "    # Excludes hits to search terms prefixed with \"non-\"\n",
    "    # Warning: this regex will exclude strings if the search term is at the immediate beginning\n",
    "    _terms = [\"[^(non\\-)]\" + term for term in _terms]\n",
    "\n",
    "    if _terms is None or len(_terms) == 0:\n",
    "        df[\"search_hit\"] = True\n",
    "        return df\n",
    "    terms = \"|\".join(_terms)\n",
    "\n",
    "    # Search all columns\n",
    "    if global_search:\n",
    "        locs = df.columns\n",
    "\n",
    "    # Check if all provided locations are valid\n",
    "    for col in locs:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError((\"Invalid column provided: \" + col))\n",
    "\n",
    "    # Hits will be a Series of Boolean values indicating one or more search hit\n",
    "    hits = pd.Series(np.zeros(df.shape[0], dtype=bool))\n",
    "    for col in locs:\n",
    "        print(\"col =\", col)\n",
    "        if df[col].dtype == \"object\":\n",
    "            sub_hits = df[col].str.lower().str.contains(terms)\n",
    "            hits = (hits == True) | (sub_hits == True)\n",
    "\n",
    "    df[\"search_hit\"] = hits\n",
    "\n",
    "    # If restrict, df is purged of rows without a search hit (True Boolean in hits)\n",
    "    if restrict:\n",
    "        reduced = df[hits].reset_index(drop=True)\n",
    "        return reduced\n",
    "\n",
    "    return df\n",
    "\n",
    "def apply_thresh(df, col, lower=None, upper=None, quantile=False):\n",
    "    # Allows slicing of data by quantile\n",
    "    if quantile:\n",
    "        lower = df[col].quantile(lower) if lower is not None else float(\"-inf\")\n",
    "        upper = df[col].quantile(upper) if upper is not None else float(\"inf\")\n",
    "    else:\n",
    "        lower = lower if lower is not None else float(\"-inf\")\n",
    "        upper = upper if upper is not None else float(\"inf\")\n",
    "\n",
    "    return df[(df[col] > lower) & (df[col] < upper)]\n",
    "\n",
    "def get_rna_df(args):\n",
    "    df = pd.read_excel(args.rna_in_path)\n",
    "    df = clean_rna_df(df, args)\n",
    "    # df = apply_thresh(df, \"AN_L2FC\", upper = 0.01, quantile=True)\n",
    "    df = search_df(df, args.terms, args.search_locs, global_search=args.universal, restrict=args.restrict)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set arguments for a given run\n",
    "df_args = ArgBin(\n",
    "                        rna_in_path_=Path(Path.cwd().parent / \"in_files\" / \"rna_seq_input.xlsx\"),\n",
    "                        prot_in_path_=Path(Path.cwd().parent / \"in_files\" / \"silac_input.xlsx\"),\n",
    "                        pair_in_path_=Path(Path.cwd().parent / \"in_files\" / \"id_dump.csv\"),\n",
    "                        rna_out_path_=Path(Path.cwd().parent / \"DataFrames\" / \"rna_seq_df.xlsx\"),\n",
    "                        prot_out_path_=Path(Path.cwd().parent / \"DataFrames\" / \"prot_df.xlsx\"),\n",
    "                        comb_out_path_=Path(Path.cwd().parent / \"DataFrames\" / \"comb_df.xlsx\"),\n",
    "                        sample_=None,\n",
    "                        terms_=None,\n",
    "                        search_locs_=\"nr_description\", \n",
    "                        universal_=False,\n",
    "                        dump_=False,\n",
    "                        restrict_=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RNA DataFrame and output to excel file\n",
    "rna_df = get_rna_df(df_args)\n",
    "rna_df.to_excel(df_args.rna_out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate SILAC DataFrame\n",
    "\n",
    "The excel file containing the SILAC results are parsed, cleaned and then restricted based on parameters provided by the user. A DataFrame containing the parsed SILAC data is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prot_df(df):\n",
    "    # Fill empty cells with placeholder\n",
    "    df.fillna(\"NaN\", inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_prot_df(args):\n",
    "    df = pd.read_excel(args.prot_in_path)\n",
    "    df = clean_prot_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Protein (SILAC) DataFrame and output to excel file\n",
    "prot_df = get_prot_df(df_args)\n",
    "prot_df.to_excel(df_args.prot_out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge RNA and SILAC DataFrames\n",
    "The script \"get_acc_uniprot_pairs.py\" has already been run to generate a txt file containing Uniprot ID-GenBank accession number pairs. These ID pairs will be used to merged associated rows from the previously constructed RNA and protein DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary from Uniprot ID: accession pairs\n",
    "accs = []\n",
    "uids = []\n",
    "names = []\n",
    "\n",
    "with open(df_args.pair_in_path, \"r\") as pair_file:\n",
    "    for line in pair_file.readlines():\n",
    "        info = line.strip().split(\",\")\n",
    "        accs.append(info[0].strip())\n",
    "        uids.append(info[1].strip())\n",
    "        names.append(info[2].strip())\n",
    "        \n",
    "    # {Uniprot ID: accession number}\n",
    "    uid_acc_dict = {uid:acc for uid, acc in zip(uids, accs)}\n",
    "    # {accession number: gene name}\n",
    "    acc_name_dict = {acc:name for acc, name in zip(accs, names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove SILAC rows with no corresponding accession number\n",
    "prot_df = prot_df.loc[prot_df[\"Majority protein IDs\"].isin(uids)]\n",
    "# Append accession numbers to protein DataFrame\n",
    "prot_df.loc[:, \"accession\"] = prot_df[\"Majority protein IDs\"].apply(lambda uid: uid_acc_dict[uid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append RNA seq DataFrame row to corresponding protein DataFrame by matching accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rna_df size before = (5988, 27)\n",
      "prot_df size before = (4449, 26)\n",
      "rna_df size after = (4442, 27)\n",
      "prot_df size after = (4442, 26)\n"
     ]
    }
   ],
   "source": [
    "# Remove accessions not found in protein DataFrame\n",
    "acc_series = pd.Series(accs)\n",
    "filt_1 = acc_series.isin(prot_df[\"accession\"])\n",
    "acc_series = acc_series.loc[filt_1]\n",
    "\n",
    "# Remove accessions not found in RNA seq DataFrame or that occur more than once in the RNA seq DataFrame\n",
    "filt_2 = acc_series.isin(rna_df[\"accession\"].drop_duplicates(keep=False))\n",
    "acc_series = acc_series.loc[filt_2]\n",
    "\n",
    "# Restrict DataFrames to those with accessions matching one in refined accs Series\n",
    "print(\"rna_df size before =\", rna_df.shape)\n",
    "print(\"prot_df size before =\", prot_df.shape)\n",
    "\n",
    "rna_df = rna_df.loc[rna_df[\"accession\"].isin(acc_series)]\n",
    "prot_df = prot_df.loc[prot_df[\"accession\"].isin(acc_series)]\n",
    "\n",
    "print(\"rna_df size after =\", rna_df.shape)\n",
    "print(\"prot_df size after =\", prot_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort both DataFrames\n",
    "rna_df = rna_df.sort_values(by=\"accession\", axis=0).reset_index(drop=True)\n",
    "prot_df = prot_df.sort_values(by=\"accession\", axis=0).reset_index(drop=True)\n",
    "\n",
    "# Prevents duplicate accession column\n",
    "prot_df.drop(columns=\"accession\", inplace=True)\n",
    "\n",
    "# Stack horizontally\n",
    "comb_df = pd.concat([rna_df, prot_df], sort=False, axis=1)\n",
    "\n",
    "# Output raw merged DataFame\n",
    "path_plus_raw = df_args.comb_out_path.parent / (df_args.comb_out_path.stem + \"_raw\" + df_args.comb_out_path.suffix)\n",
    "comb_df.to_excel(path_plus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets gene name from dictionary constructed from rows of id_dump.csv\n",
    "comb_df[\"gene\"] = comb_df[\"accession\"].apply(lambda acc: acc_name_dict[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary columns\n",
    "drop_cols = [\n",
    "                \"AS_1_FPKM\", \"AS_2_FPKM\", \"AS_3_FPKM\", \"NS_1_FPKM\", \"NS_2_FPKM\", \"NS_3_FPKM\", \"YPD_1_FPKM\", \n",
    "                \"YPD_2_FPKM\", \"YPD_3_FPKM\", \"Peptides\", \"Unique peptides\", \"Sequence coverage [%]\",\n",
    "                \"Unique sequence coverage [%]\", \"Mol. weight [kDa]\", \"Intensity\", \"Intensity L\", \"Intensity M\", \n",
    "                \"Intensity H\", \"Protein IDs\", \"Gene names\"\n",
    "            ]\n",
    "\n",
    "# Drop all columns labeled \"Unnamed X\"\n",
    "unnamed = [col for col in comb_df.columns if \"Unnamed\" in col]\n",
    "drop_cols += unnamed\n",
    "\n",
    "comb_df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "comb_df = comb_df.rename(columns={\n",
    "                                    \"gene\": \"gene\",\"gene_id\": \"transcript_id\", \"gene_name\": \"extended_name_rna\", \"AS_mean\": \"AS_rna_mean\", \n",
    "                                    \"AS_stdev\": \"AS_rna_stdev\", \"NS_mean\": \"NS_rna_mean\", \"NS_stdev\": \"NS_rna_stdev\", \"YPD_mean\": \"YPD_rna_mean\", \n",
    "                                    \"YPD_stdev\": \"YPD_rna_stdev\", \"YA_L2FC\": \"YA_rna_L2FC\", \"YN_L2FC\": \"YN_rna_L2FC\", \"AN_L2FC\": \"AN_rna_L2FC\", \n",
    "                                    \"Cellular Component\": \"cellular_component\", \"mol_func\": \"function\", \"SD-N/SD_1h\": \"SD-N/SD_1h_prot\", \n",
    "                                    \"SD-N/SD_6h\": \"SD-N/SD_6h_prot\", \"SD-AA/SD_1h\": \"SD-AA/SD_1h_prot\", \"SD-AA/SD_6h\": \"SD-AA/SD_6h_prot\", \n",
    "                                    \"SD-AA/SD-N_1h\": \"SD-AA/SD-N_1h_prot\", \"SD-AA/SD-N_6h\": \"SD-AA/SD-N_6h_prot\", \"Razor + unique peptides\": \"total_peptides\", \n",
    "                                    \"Unique + razor sequence coverage [%]\": \"total_percent_sequence_coverage\", \"Q-value\": \"q-value\", \n",
    "                                    \"Score\": \"score\", \"Majority protein IDs\": \"major_prot_id\", \"Protein names\": \"extended_name_prot\", \n",
    "                                 }\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "comb_df = comb_df[[\n",
    "           \"gene\", \"extended_name_rna\", \"extended_name_prot\", \"NS_rna_mean\", \"NS_rna_stdev\", \"AS_rna_mean\",\n",
    "           \"AS_rna_stdev\", \"YPD_rna_mean\", \"YPD_rna_stdev\", \"YN_rna_L2FC\", \"YA_rna_L2FC\", \"AN_rna_L2FC\",\n",
    "           \"SD-N/SD_1h_prot\", \"SD-N/SD_6h_prot\", \"SD-AA/SD_1h_prot\", \"SD-AA/SD_6h_prot\", \"SD-AA/SD-N_1h_prot\",\n",
    "           \"SD-AA/SD-N_6h_prot\", \"total_peptides\", \"total_percent_sequence_coverage\", \"q-value\", \"score\", \n",
    "           \"transcript_id\", \"accession\", \"major_prot_id\", \"nr_description\", \"cellular_component\", \"function\", \n",
    "           \"bio_process\", \"kegg_orth\", \"search_hit\",\n",
    "\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to gene name\n",
    "comb_df.set_index(\"gene\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cleaned DataFrame to excel file\n",
    "comb_df.to_excel(df_args.comb_out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
